---
title: "CSP571 Summer 2022 Project. Gap Phenomenon in Stock Market: Evaluating the Significance of Price Gaps in Predicting Future Returns Using Statistical and Machine Learning Techniques"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    toc_depth: 6
author: Oleksandr Shashkov and Santosh Chaluvaraju
        Illinois Institute of Technology
---

# Libraries
```{r}
library(tibble)
library(collections)
library(tidyverse)
library(tidyquant)
library(lubridate)
library(dplyr)
library(timetk)
library(quantmod)
library(corrplot)
library(zoom)
library(caret)
library(Metrics)
library(glmnet)
```

# 1. Removing Survival Bias

```{r}
# load the S&P500 historical composition
SnP_components_raw <- read.csv(file=file.choose())
```
```{r}
# form a set of all stocks tickers
tickers_set <- c()
for (composition in SnP_components_raw$tickers) {
  curr_composition <- strsplit(composition,split = ",")
  tickers_set <- unique(c(tickers_set,curr_composition[[1]]))
}
```
```{r}
# form a dictionary where a key is a ticker 
# and a value is a list of data ranges when a stock was in the S&P index
sp500_composition <- dict()
counter = 1
# iterate through the list of historical S&P components
for (tcr in tickers_set) {
  cat("Processing ticker:",tcr,"(",counter,")","\n")
  listed <- FALSE
  # declare time stamp variables
  start_timestamp <- Sys.Date()
  last_timestamp <- Sys.Date()
  # list of ranges when the current stock was a part of S&P index
  range_list <- list()
  # iterate through the time steps
  for (i in 1:nrow(SnP_components_raw)) {
    timestep <- SnP_components_raw[i,]
    curr_timestamp <- timestep$date[[1]][1]
    if (!(tcr %in% strsplit(timestep$tickers,split = ",")[[1]])){
      # ticker is not in the current composition
      if (listed){# stock was listed before but now it is not
        # form an entry in the list containing start and stop time stamps
        range_entry <- list(start_timestamp,last_timestamp)
        # add it to the list of ranges
        range_list <- append(range_list, list(range_entry))
        
        listed = FALSE
      }
    } else {# ticker is in the current composition
      if (!listed){# stock was not listed previously
        # start tracking new range
        start_timestamp <- curr_timestamp
        listed = TRUE
      }
    }
    last_timestamp <- curr_timestamp
  }
  # we are done with current ticker
  if (listed){  # need to check if the range needs to be closed
    # form an entry in the list containing start and stop time stamps
    range_entry <- list(start_timestamp,last_timestamp)
    # add it to the list of ranges
    range_list <- append(range_list, list(range_entry))
  }
  # add ticker and ranges to global dictionary
  sp500_composition$set(tcr,c(range_list))
  counter <- counter + 1
}

```

# 2. Downloading Data
## 2.1 Downloading Stocks Data
```{r}
# process dictionary to download stocks data for the ranges
for (stock in sp500_composition$keys()) {
  for (rng in sp500_composition$get(stock)){
    cat("ticker:",stock,"start:",
        format.Date(rng[[1]][1]),
        "stop:",format.Date(rng[[2]][1]),"\n")
    # download stocks data here having ticker and time stamps. tq_get returns data in tibble form, convert tibble data into dataframe before saving
    stock_prices_df <- as.data.frame(tq_get(stock, from = rng[[1]][1], to = rng[[2]][1]))
    # save it to the file
    file_name <- paste(stock,rng[[1]][1],"-",rng[[2]][1], sep = "-")
    #Putting all the files inside data folder
    file_name <- paste("data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    write.csv(stock_prices_df , file_name, row.names = FALSE)
  }
}
```

## 2.2 Downloading S&P500 index data
```{r}
# get S&P500 data for the entire data range:
GSPC <- getSymbols("^GSPC", auto.assign=FALSE, from="1996-01-01", src="yahoo")
GSPC_data <- data.frame(symbol='GSPC',date=time(GSPC),as.matrix(GSPC))
colnames(GSPC_data ) <- c("symbol","date","open","high","low","close","volume","adjusted")
write.csv(GSPC_data,"C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\data\\GSPC.csv", row.names = FALSE)
```

# 3. Data Processing
## 3.1 Loading Saved Data
```{r}
path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data" 
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)

for (file in filesList) {
  #Remove files if it contains less than or equal to 2 columns
  if(ncol(read.csv(file)) <= 2){
    file.remove(file)
  }
  
}
```

Get all CSV files along with their full path
```{r}
#path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/data"
path <- "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\data"
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)
```

## 3.2 Gap Detection
```{r}
detect_gaps <- function(last_h, last_l, h, l)
{
  gap_size = 0.0
  gap_type = "NONE"
  if(last_l > h){
    gap_type = "DOWN"
    gap_size = (h - last_l)/last_l
  }
  else if(last_h < l){
    gap_type = "UP"
    #gap_size = (l - last_h)/last_h
    gap_size = as.numeric((l - last_h)/last_h)    
  }
  gap_list = list(gap_type, gap_size)
  
  return (gap_list)
}
```

## 3.3 Preprocessing S&P 500 index data
```{r}
# loading data and calculating overnight returns for S&P500 index
spxdf <- read.csv("data/GSPC.csv")
rownames(spxdf) <- spxdf$date
for(i in 1:nrow(spxdf)){
      if(i == 1){
        # fake overnight return with intraday for first entry
        spxdf$return[i] <- (spxdf$close[i]-spxdf$open[i])/spxdf$open[i]
      }
      else{
        spxdf$return[i] <- (spxdf$adjusted[i]-spxdf$adjusted[i-1])/spxdf$adjusted[i-1]
      }
}

#Putting pre processed file inside pre_processed_data folder
file_name <- paste("GSPC", "preprocessed", sep = "_" )
file_name <- paste("pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
spxdf <- apply(spxdf,2,as.character)
write.csv(spxdf , file_name, row.names = FALSE)

# reload spxdf
spxdf <- read.csv("pre_processed_data/GSPC_preprocessed.csv")
rownames(spxdf) <- spxdf$date
```


## 3.4 Preprocessing Stocks Data
Detecting gaps and types, Calculating ranges, relative volume, daily returns and adjusted daily returns and adding it into new columns 
```{r}
for (file in filesList) {
  # load CSV file  
  df <- read.csv(file)
  print(file)
  
  df <- df[!is.na(df$high),]
  df <- df[!is.na(df$low),]
  # Perform preprocessing only if the data frame has more than 25 rows else ignore
  if(nrow(df) > 25){
    
    gap_list <- list()
    
    for(i in 1:nrow(df)){
      if(i == 1){
        gap_list[[i]] <- list("NONE", 0.0)
        df$vol_change[i] <- 0.0
        # fake overnight return with intraday for first entry
        df$return[i] <- (df$close[i]-df$open[i])/df$open[i]
      }
      else{
        gap_list[[i]] <- detect_gaps(df$high[i-1], df$low[i-1], df$high[i], df$low[i])
        # calculating relative volume
        df$vol_change[i] <- (df$volume[i] - df$volume[i-1])/df$volume[i-1]
        # calculating daily returns
        # We need overnight return, not intraday
        # And we need to use adjusted close for that
        df$return[i] <- (df$adjusted[i]-df$adjusted[i-1])/df$adjusted[i-1]
      }
      
      #calculating adjusted returns
      df$adjusted_return[i] <- df$return[i] - spxdf$return[which(rownames(spxdf)==df$date[i])]
      
    }
    df_temp <- as.data.frame(do.call(rbind, gap_list))
    colnames(df_temp) <- c("gap_type", "gap_size")
    df <- cbind(df, df_temp)
    #adding range column
    df$range <- (df$high - df$low)/df$low
    
    # extract day of the week and month as potential features
    df$weekday <- wday(df$date, week_start=1)
    df$month <- month(df$date)
    
    # calculate "candle body metric"
    df$candle_body_metric <- (df$close - df$open)/df$open

    # adding lags and leads
    selected_cols <- c(
      "vol_change","return","adjusted_return","range","weekday","month","candle_body_metric")
    lags_leads <- (-10:10)[as.logical( -10:10 != 0)]# -10...-1 1...10 - omit 0 
    df <- df %>% tk_augment_lags(contains(selected_cols), .lags = lags_leads)    

    # cleaning up rows with NAs
    df <- na.omit(df)

    #Putting all the pre processed files inside pre_processed_data folder
    file_name <- paste(sub('\\.csv$', '', basename(file)), "preprocessed", sep = "_" )
    file_name <- paste("pre_processed_data",file_name,sep = "/")
    file_name <- paste(file_name,"csv", sep = ".")
    df <- apply(df,2,as.character)
    write.csv(df , file_name, row.names = FALSE)
  }
}
```

```{r}
# Save all the gaps into a single data frame, preserve it into CSV
#path <- "/home/santosh/Desktop/MASTERS/STUDIES_MSDS/SEM_2_summer/Data_preparation_and_analysis/PROJECT/git_work/Gap-Phenomenon-in-Stock-Market/pre_processed_data"
path <- "C:\\Users\\Alex\\Documents\\IIT\\CSP571\\Assignments\\Project\\Gap-Phenomenon-in-Stock-Market\\pre_processed_data"
filesList <- list.files(path=path, pattern=NULL, all.files=FALSE, full.names=TRUE)
# remove file describing index
filesList <- filesList[!grepl("GSPC",filesList)]
final_stock_df <- data.frame()
for (file in filesList) {
  print(file)
  df <- read.csv(file)
  df <- df[df$gap_type !='NONE',]
  final_stock_df <- rbind(final_stock_df, df)
}
  
print(nrow(final_stock_df))

#Putting all the pre processed files inside pre_processed_data folder
file_name <- paste("final", "preprocessed", sep = "_" )
file_name <- paste("final_pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
write.csv(final_stock_df , file_name, row.names = FALSE)
```

```{r}
#cleanup
rm(list=ls())
```

## 3.5 Final Data Clenup
```{r}
file <- file.choose()
gaps_df <- read.csv(file)
```

```{r}
dim(gaps_df)
summary(gaps_df)
```
The data has to be cleaned as there are: 
1) inf values in vol_change column and lags
2) Enormously high returns in some rows and lags
3) Enormously high ranges in some rows and lags
4) Enormously high gaps in some rows and lags
5) gap_type must be a factor
6) weekday and month and their lags must be factors

```{r}
summary(gaps_df$vol_change)
quantile(gaps_df$vol_change,probs=c(.01,.99))
hist(gaps_df$vol_change, breaks=1000, main = "Volume change distirbution before the cleanup")
hist(log(gaps_df$vol_change), breaks=1000, main = "Log Volume change distirbution before the cleanup")
```

```{r}
# removing rows with infinite and unrealistic values of vol_change and its lags
# let's limit it within at least 98% range:  ( -0.642356 < and < 8.261169 )
mx = 8.27
mn = -0.64
gaps_df <- gaps_df[gaps_df$vol_change < mx &  gaps_df$vol_change > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.10 < mx &  gaps_df$vol_change_lag.10 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.9 < mx &  gaps_df$vol_change_lag.9 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.8 < mx &  gaps_df$vol_change_lag.8 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.7 < mx &  gaps_df$vol_change_lag.7 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.6 < mx &  gaps_df$vol_change_lag.6 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.5 < mx &  gaps_df$vol_change_lag.5 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.4 < mx &  gaps_df$vol_change_lag.4 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.3 < mx &  gaps_df$vol_change_lag.3 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.2 < mx &  gaps_df$vol_change_lag.2 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag.1 < mx &  gaps_df$vol_change_lag.1 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag10 < mx &  gaps_df$vol_change_lag10 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag9 < mx &  gaps_df$vol_change_lag9 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag8 < mx &  gaps_df$vol_change_lag8 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag7 < mx &  gaps_df$vol_change_lag7 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag6 < mx &  gaps_df$vol_change_lag6 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag5 < mx &  gaps_df$vol_change_lag5 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag4 < mx &  gaps_df$vol_change_lag4 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag3 < mx &  gaps_df$vol_change_lag3 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag2 < mx &  gaps_df$vol_change_lag2 > mn,]
gaps_df <- gaps_df[gaps_df$vol_change_lag1 < mx &  gaps_df$vol_change_lag1 > mn,]
```

```{r}
summary(gaps_df$vol_change)
hist(gaps_df$vol_change, breaks=100, main = "Volume change distribution after the cleanup")
```
This took care of all the unreasonable values!!!

```{r}
gaps_df$gap_type <- as.factor(gaps_df$gap_type)
gaps_df$weekday <- as.factor(gaps_df$weekday)
gaps_df$month <- as.factor(gaps_df$month)

gaps_df$weekday_lag.10 <- as.factor(gaps_df$weekday_lag.10)
gaps_df$month_lag.10 <- as.factor(gaps_df$month_lag.10)
gaps_df$weekday_lag.9 <- as.factor(gaps_df$weekday_lag.9)
gaps_df$month_lag.9 <- as.factor(gaps_df$month_lag.9)
gaps_df$weekday_lag.8 <- as.factor(gaps_df$weekday_lag.8)
gaps_df$month_lag.8 <- as.factor(gaps_df$month_lag.8)
gaps_df$weekday_lag.7 <- as.factor(gaps_df$weekday_lag.7)
gaps_df$month_lag.7 <- as.factor(gaps_df$month_lag.7)
gaps_df$weekday_lag.6 <- as.factor(gaps_df$weekday_lag.6)
gaps_df$month_lag.6 <- as.factor(gaps_df$month_lag.6)
gaps_df$weekday_lag.5 <- as.factor(gaps_df$weekday_lag.5)
gaps_df$month_lag.5 <- as.factor(gaps_df$month_lag.5)
gaps_df$weekday_lag.4 <- as.factor(gaps_df$weekday_lag.4)
gaps_df$month_lag.4 <- as.factor(gaps_df$month_lag.4)
gaps_df$weekday_lag.3 <- as.factor(gaps_df$weekday_lag.3)
gaps_df$month_lag.3 <- as.factor(gaps_df$month_lag.3)
gaps_df$weekday_lag.2 <- as.factor(gaps_df$weekday_lag.2)
gaps_df$month_lag.2 <- as.factor(gaps_df$month_lag.2)
gaps_df$weekday_lag.1 <- as.factor(gaps_df$weekday_lag.1)
gaps_df$month_lag.1 <- as.factor(gaps_df$month_lag.1)

gaps_df$weekday_lag10 <- as.factor(gaps_df$weekday_lag10)
gaps_df$month_lag10 <- as.factor(gaps_df$month_lag10)
gaps_df$weekday_lag9 <- as.factor(gaps_df$weekday_lag9)
gaps_df$month_lag9 <- as.factor(gaps_df$month_lag9)
gaps_df$weekday_lag8 <- as.factor(gaps_df$weekday_lag8)
gaps_df$month_lag8 <- as.factor(gaps_df$month_lag8)
gaps_df$weekday_lag7 <- as.factor(gaps_df$weekday_lag7)
gaps_df$month_lag7 <- as.factor(gaps_df$month_lag7)
gaps_df$weekday_lag6 <- as.factor(gaps_df$weekday_lag6)
gaps_df$month_lag6 <- as.factor(gaps_df$month_lag6)
gaps_df$weekday_lag5 <- as.factor(gaps_df$weekday_lag5)
gaps_df$month_lag5 <- as.factor(gaps_df$month_lag5)
gaps_df$weekday_lag4 <- as.factor(gaps_df$weekday_lag4)
gaps_df$month_lag4 <- as.factor(gaps_df$month_lag4)
gaps_df$weekday_lag3 <- as.factor(gaps_df$weekday_lag3)
gaps_df$month_lag3 <- as.factor(gaps_df$month_lag3)
gaps_df$weekday_lag2 <- as.factor(gaps_df$weekday_lag2)
gaps_df$month_lag2 <- as.factor(gaps_df$month_lag2)
gaps_df$weekday_lag1 <- as.factor(gaps_df$weekday_lag1)
gaps_df$month_lag1 <- as.factor(gaps_df$month_lag1)

summary(gaps_df)
```
```{r}
# Saving clean data frame
file_name <- paste("clean", "preprocessed", sep = "_" )
file_name <- paste("final_pre_processed_data",file_name,sep = "/")
file_name <- paste(file_name,"csv", sep = ".")
write.csv(gaps_df , file_name, row.names = FALSE)
```
```{r}
#cleanup
rm(list=ls())
```
# 4. Data Analysis
```{r}
# load clean dataframe with gaps
file <- file.choose()
gaps_df <- read.csv(file)
gaps_df$gap_type <- as.factor(gaps_df$gap_type)
gaps_df$weekday <- as.factor(gaps_df$weekday)
gaps_df$month <- as.factor(gaps_df$month)

gaps_df$weekday_lag.10 <- as.factor(gaps_df$weekday_lag.10)
gaps_df$month_lag.10 <- as.factor(gaps_df$month_lag.10)
gaps_df$weekday_lag.9 <- as.factor(gaps_df$weekday_lag.9)
gaps_df$month_lag.9 <- as.factor(gaps_df$month_lag.9)
gaps_df$weekday_lag.8 <- as.factor(gaps_df$weekday_lag.8)
gaps_df$month_lag.8 <- as.factor(gaps_df$month_lag.8)
gaps_df$weekday_lag.7 <- as.factor(gaps_df$weekday_lag.7)
gaps_df$month_lag.7 <- as.factor(gaps_df$month_lag.7)
gaps_df$weekday_lag.6 <- as.factor(gaps_df$weekday_lag.6)
gaps_df$month_lag.6 <- as.factor(gaps_df$month_lag.6)
gaps_df$weekday_lag.5 <- as.factor(gaps_df$weekday_lag.5)
gaps_df$month_lag.5 <- as.factor(gaps_df$month_lag.5)
gaps_df$weekday_lag.4 <- as.factor(gaps_df$weekday_lag.4)
gaps_df$month_lag.4 <- as.factor(gaps_df$month_lag.4)
gaps_df$weekday_lag.3 <- as.factor(gaps_df$weekday_lag.3)
gaps_df$month_lag.3 <- as.factor(gaps_df$month_lag.3)
gaps_df$weekday_lag.2 <- as.factor(gaps_df$weekday_lag.2)
gaps_df$month_lag.2 <- as.factor(gaps_df$month_lag.2)
gaps_df$weekday_lag.1 <- as.factor(gaps_df$weekday_lag.1)
gaps_df$month_lag.1 <- as.factor(gaps_df$month_lag.1)

gaps_df$weekday_lag10 <- as.factor(gaps_df$weekday_lag10)
gaps_df$month_lag10 <- as.factor(gaps_df$month_lag10)
gaps_df$weekday_lag9 <- as.factor(gaps_df$weekday_lag9)
gaps_df$month_lag9 <- as.factor(gaps_df$month_lag9)
gaps_df$weekday_lag8 <- as.factor(gaps_df$weekday_lag8)
gaps_df$month_lag8 <- as.factor(gaps_df$month_lag8)
gaps_df$weekday_lag7 <- as.factor(gaps_df$weekday_lag7)
gaps_df$month_lag7 <- as.factor(gaps_df$month_lag7)
gaps_df$weekday_lag6 <- as.factor(gaps_df$weekday_lag6)
gaps_df$month_lag6 <- as.factor(gaps_df$month_lag6)
gaps_df$weekday_lag5 <- as.factor(gaps_df$weekday_lag5)
gaps_df$month_lag5 <- as.factor(gaps_df$month_lag5)
gaps_df$weekday_lag4 <- as.factor(gaps_df$weekday_lag4)
gaps_df$month_lag4 <- as.factor(gaps_df$month_lag4)
gaps_df$weekday_lag3 <- as.factor(gaps_df$weekday_lag3)
gaps_df$month_lag3 <- as.factor(gaps_df$month_lag3)
gaps_df$weekday_lag2 <- as.factor(gaps_df$weekday_lag2)
gaps_df$month_lag2 <- as.factor(gaps_df$month_lag2)
gaps_df$weekday_lag1 <- as.factor(gaps_df$weekday_lag1)
gaps_df$month_lag1 <- as.factor(gaps_df$month_lag1)
rm(file)
```

## 4.1 Gaps Statistics
```{r}
total_gaps <- nrow(gaps_df)
cat("Total number of gaps detected:", total_gaps, "\n")
gap_types <- summary(gaps_df$gap_type)
up_gaps <-unname(gap_types['UP'])
down_gaps <- unname(gap_types['DOWN'])
cat("Gaps UP:", up_gaps,round(100*up_gaps/total_gaps,digits = 2),"%","\n")
cat("Gaps DOWN:", down_gaps,round(100*down_gaps/total_gaps,digits = 2),"%","\n")
```
```{r}
# gaps per weekday
cat("Gaps per weekday:\n")
round(prop.table(table(gaps_df$weekday)) * 100, digits = 2)
cat("Gaps UP per weekday:\n")
round(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='UP'])) * 100, digits = 2)
cat("Gaps DOWN per weekday:\n")
round(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='DOWN'])) * 100, digits = 2)
xl <- "Day of the week"
yl <- "Percentage"
par(mfrow=c(2,2))
barplot(prop.table(table(gaps_df$weekday)) * 100, main = "Gaps per weekday", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='UP'])) * 100, main = "Gaps UP per weekday", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$weekday[gaps_df$gap_type =='DOWN'])) * 100, main = "Gaps DOWN per weekday", xlab = xl, ylab = yl)
```
```{r}
# gaps per month
cat("Gaps per month:\n")
round(prop.table(table(gaps_df$month)) * 100, digits = 2)
cat("Gaps UP per month:\n")
round(prop.table(table(gaps_df$month[gaps_df$gap_type =='UP'])) * 100, digits = 2)
cat("Gaps DOWN per month:\n")
round(prop.table(table(gaps_df$month[gaps_df$gap_type =='DOWN'])) * 100, digits = 2)
xl <- "Month of the year"
yl <- "Percentage"
par(mfrow=c(2,2))
barplot(prop.table(table(gaps_df$month)) * 100, main = "Gaps per month", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$month[gaps_df$gap_type =='UP'])) * 100, main = "Gaps UP per month", xlab = xl, ylab = yl)
barplot(prop.table(table(gaps_df$month[gaps_df$gap_type =='DOWN'])) * 100, main = "Gaps DOWN per month", xlab = xl, ylab = yl)
```
```{r}
# Gap sizes
qu <- quantile(gaps_df$gap_size[gaps_df$gap_size > 0],probs=c(.05,.95))
ql <- quantile(gaps_df$gap_size[gaps_df$gap_size < 0],probs=c(.05,.95))
xl <- "Gap size, %"
yl <- "Frequency"
par(mfrow=c(2,2))
hist(100*gaps_df$gap_size[gaps_df$gap_size > 0], breaks=10000, main = "Gap UP size distribution, all", xlab = xl, ylab = yl, col = "green")
hist(-100*gaps_df$gap_size[gaps_df$gap_size < 0], breaks=10000, main = "Gap DOWN size distribution, all", xlab = xl, ylab = yl, col = "red")
hist(100*gaps_df$gap_size[gaps_df$gap_size > 0 & gaps_df$gap_size < unname(qu["95%"])], breaks=50, main = "Gap UP size distribution, 95%", xlab = xl, ylab = yl, col = "green")
hist(-100*gaps_df$gap_size[gaps_df$gap_size < 0 & gaps_df$gap_size > unname(ql["5%"])], breaks=50, main = "Gap DOWN size distribution. 95%", xlab = xl, ylab = yl, col = "red")
qu
ql
```

```{r}
# Gap candle range
q <- quantile(gaps_df$range,probs=c(.01,.99))
qu <- quantile(gaps_df$range[gaps_df$gap_type == "UP"],probs=c(.01,.99))
qd <- quantile(gaps_df$range[gaps_df$gap_type == "DOWN"],probs=c(.01,.99))
xl <- "Range, %"
yl <- "Frequency"
par(mfrow=c(3,2))
hist(100*gaps_df$range, breaks=10000, main = "Gap candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$range < unname(q["99%"])], breaks=50, main = "Gap candle range distribution, 99%", xlab = xl, ylab = yl)

hist(100*gaps_df$range[gaps_df$gap_type == "UP"], breaks=10000, main = "Gap UP candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$gap_type == "UP" & gaps_df$range < unname(qu["99%"])], breaks=50, main = "Gap UP candle range distribution, 99%", xlab = xl, ylab = yl, col = "green")

hist(100*gaps_df$range[gaps_df$gap_type == "DOWN"], breaks=10000, main = "Gap DOWN candle range distribution, all", xlab = xl, ylab = yl)
hist(100*gaps_df$range[gaps_df$gap_type == "DOWN" & gaps_df$range < unname(qd["99%"])], breaks=50, main = "Gap DOWN candle range distribution, 99%", xlab = xl, ylab = yl, col = "red")
```
```{r}
# Gap candle body metric
q <- quantile(gaps_df$candle_body_metric,probs=c(.01,.99))
qu <- quantile(gaps_df$candle_body_metric[gaps_df$gap_type == "UP"],probs=c(.01,.99))
qd <- quantile(gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN"],probs=c(.01,.99))
xl <- "Body Metric, %"
yl <- "Frequency"
par(mfrow=c(3,2))
hist(100*gaps_df$candle_body_metric[gaps_df$candle_body_metric < unname(q["99%"]) & gaps_df$candle_body_metric > unname(q["1%"])], breaks=50, main = "Gap candle body metric distribution", xlab = xl, ylab = yl)
boxplot(100*gaps_df$candle_body_metric, horizontal = TRUE, main = "Gap candle body metric distribution")

hist(100*gaps_df$candle_body_metric[gaps_df$gap_type == "UP" & gaps_df$candle_body_metric < unname(qu["99%"]) & gaps_df$candle_body_metric > unname(qu["1%"])], breaks=50, main = "Gap UP candle body metric distribution", xlab = xl, ylab = yl,col = "green")
boxplot(100*gaps_df$candle_body_metric[gaps_df$gap_type == "UP" & gaps_df$candle_body_metric < unname(qu["99%"])& gaps_df$candle_body_metric > unname(qu["1%"])], horizontal = TRUE, main = "Gap UP candle body metric distribution", col = "green")

hist(100*gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN" & gaps_df$candle_body_metric < unname(qd["99%"]) & gaps_df$candle_body_metric > unname(qd["1%"])], breaks=50, main = "Gap DOWN candle body metric distribution", xlab = xl, ylab = yl,col = "red")
boxplot(100*gaps_df$candle_body_metric[gaps_df$gap_type == "DOWN" & gaps_df$candle_body_metric < unname(qd["99%"])& gaps_df$candle_body_metric > unname(qd["1%"])], horizontal = TRUE, main = "Gap DOWN candle body metric distribution", col = "red")
```

## 4.2 Correlations
```{r}
# Consider Correlations for quantitative variables
# Create a sub frame
cleandf <- gaps_df
cols <- colnames(cleandf)
cols
cols <- cols[- c(1,2,3,4,5,6,7,8,11,12,15,16,18:81,83:87,90,92,93,97,99,100,104,106,107,111,113,114,118,120,121,125,127,128,132,134,135,139,141,142,146,148,149,153,155,156)]
cols
subCleanDf <- cleandf[, cols]
cm <- cor(subCleanDf)
corrplot(cm, tl.cex=0.5)
#zm()
```

# 5. Modeling

## 5.1 Linear Model Experiments
```{r}
# reset the dataframe, include categorical predictors: day and month
cleandf <- gaps_df
cols <- colnames(cleandf)
cols <- cols[- c(1,2,3,4,5,6,7,8,11,18:81,83:87,90,92,93,97,99,100,104,106,107,111,113,114,118,120,121,125,127,128,132,134,135,139,141,142,146,148,149,153,155,156)]
subCleanDf <- cleandf[, cols]
set.seed(1)
train <- createDataPartition(subCleanDf$return_lag.1, p = 0.8, list = FALSE)
stockdf_train <- subCleanDf[train, ]
stockdf_test <- subCleanDf[-train, ]
stockdf_train_model_ln <- lm(return_lag.1 ~., data = stockdf_train)
smry <- summary(stockdf_train_model_ln)
print(smry)
confint(stockdf_train_model_ln)
```

Based on p-values and confidence intervals the following predictors seem to be insignificant in linear regression model:

candle_body_metric
candle_body_metric_lag5

range_lag2
range_lag3
range_lag6
range_lag9

vol_change_lag5
vol_change_lag6
vol_change_lag8
vol_change_lag9

return_lag5
return_lag6
return_lag8


```{r}
predictTrain <- predict(stockdf_train_model_ln, newdata = stockdf_train)
cat("Training MSE" , mse(stockdf_train$return_lag.1, predictTrain), "\n")
cat("Training RMSE" , rmse(stockdf_train$return_lag.1, predictTrain), "\n")
cat("Model's R-squared" , smry$r.squared, "\n")
```
Performance metrics on test data linear regression:
```{r}
predictTest <- predict(stockdf_train_model_ln, newdata = stockdf_test)
cat("Test MSE" , mse(stockdf_test$return_lag.1, predictTest), "\n")
cat("Test RMSE" , rmse(stockdf_test$return_lag.1, predictTest), "\n")
```
Based on R-squared the linear model is not good. That's is OK as we just wanted to see F-statistics to help with analyzing the significance of the predictors

## 5.2 Lasso Regression Experiments

```{r}
# Let's try Lasso Regression
x_train <- model.matrix(stockdf_train$return_lag.1 ~., data = stockdf_train)[, -9]
y_train <- stockdf_train$return_lag.1
# display how coefficients change with lambda
lasso_model <- glmnet(x_train, y_train, alpha = 1)
plot(lasso_model, "lambda")
plot(lasso_model, "norm")
#coef(lasso_model)
grid <- 10^seq(0, -7, length = 100)
lasso_cv_model <- cv.glmnet(x_train, y_train, alpha = 1, lambda = grid)
plot(lasso_cv_model)
best_lambda <- lasso_cv_model$lambda.min
cat("Best Lambda: ", best_lambda, "\n")
summary(lasso_cv_model)
coef(lasso_cv_model)
# get test performance
x_test <- model.matrix(stockdf_test$return_lag.1~. , data = stockdf_test)[, -9]
lasso_pred <- predict(lasso_cv_model, s = best_lambda, newx = x_test)
test_mse <- mse(stockdf_test$return_lag.1, lasso_pred)
cat("Test MSE" , test_mse, "\n")
```
Lasso regression rendered the following variables as not significant:

gap_type
gap_size

vol_change
vol_change_lag1
vol_change_lag2
vol_change_lag3
vol_change_lag4
vol_change_lag5
vol_change_lag6
vol_change_lag7
vol_change_lag8
vol_change_lag9
vol_change_lag10

return
return_lag2
return_lag5
return_lag6
return_lag8
return_lag9
return_lag10


range_lag2
range_lag3
range_lag4
range_lag5
range_lag6
range_lag7
range_lag8
range_lag9
range_lag10

candle_body_metric_lag2
candle_body_metric_lag3
candle_body_metric_lag4
candle_body_metric_lag5
candle_body_metric_lag6
candle_body_metric_lag7
candle_body_metric_lag8
candle_body_metric_lag9
candle_body_metric_lag10

This finding mostly matches observations for simple linear regression model. It seems like past values of vol_change does not play any role in predicting future return and all the other predictors do not demonstrate predicting power past the lag of 2 days. However, this is based on assumption of linear relationship. We do expect non-linear relationship instead. Therefore, it would be reasonable to still maintain the entire set of predictors to evaluate non-linear or recurrent model

```{r}
#cleanup
rm(list=ls())
```

## 5.3 TODO: Neural Netwrok Model with LSTM elements